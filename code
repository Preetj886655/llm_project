!pip install -U langchain-huggingface langchain-community langchain-core langchain langgraph 

from langchain_huggingface import ChatHuggingFace,HuggingFaceEndpoint,HuggingFaceEmbeddings

import os
os.environ['HUGGINGFACEHUB_API_TOKEN']="hF_"
llm=HuggingFaceEndpoint(
    repo_id="deepseek-ai/DeepSeek-V3.2",
    task="text-generation"
)
model=ChatHuggingFace(llm=llm)

from langchain_community.document_loaders import PyPDFLoader

pip install pypdf

loader=PyPDFLoader('/content/22MEB0A46_TFTTHINK.pdf')
data=loader.load()

from langchain_text_splitters import RecursiveCharacterTextSplitter

splitter=RecursiveCharacterTextSplitter(chunk_size=100,chunk_overlap=30)

chunk=splitter.split_documents(data)



embedding=HuggingFaceEmbeddings(
    model="sentence-transformers/all-MiniLM-L6-v2"
)

x=embedding.embed_documents([doc.page_content for doc in chunk])

from langchain_community.vectorstores import FAISS

pip install faiss-cpu

vector_store=FAISS.from_documents(chunk,embedding)

vector_store

retriever=vector_store.as_retriever(search_type='similarity',search_kwargs={'k':4})

retriever

from typing import TypedDict,Annotated
from langchain_core.messages import HumanMessage,BaseMessage
from langgraph.graph.message import add_messages



class chatstate(TypedDict):
  messages:Annotated[list[BaseMessage],add_messages]

from langchain_core.tools import tool

@tool
def rag_tool(query):
  """
  Retrieve the relevant information from pdf
  """
  res=retriever.invoke(query)
  context=[docs.page_content for docs in res]
  metadata=[docs.metadata for docs in res]
  return {
      "query":query,
      "context":context,
      "metadata":metadata
  }

tools=[rag_tool]
model_with_tool=model.bind_tools(tools)

from langgraph.prebuilt import ToolNode,tools_condition

tool_node=ToolNode(tools)

from langgraph.graph import StateGraph,START,END

def chat_node(state:chatstate):
  message=state['messages']
  res=model_with_tool.invoke(message)
  return {'messages':[res]}

graph=StateGraph(chatstate)
graph.add_node('chat_node',chat_node)
graph.add_node('tools',tool_node)

graph.add_edge(START,'chat_node')
graph.add_conditional_edges('chat_node',tools_condition)
graph.add_edge('tools','chat_node')
chatbot=graph.compile()

prompt=input("user Type Message:- ")
res=chatbot.invoke({
    'messages':[
        HumanMessage(
            content=prompt
        )
    ]
})
print(res['messages'][-1].content)



